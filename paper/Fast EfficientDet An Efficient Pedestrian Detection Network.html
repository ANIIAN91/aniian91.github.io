<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>ANIIAN'S DIARY | ANIIAN'S DIARY</title>
    <meta name="description" content="Record the learning of relevant deep learning, Linux, shell, etc.">
    <meta name="generator" content="VitePress v1.0.0-rc.31">
    <link rel="preload stylesheet" href="/assets/style.DR1GGnC4.css" as="style">
    
    <script type="module" src="/assets/app.fHvVg2SD.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Bu8hRsVA.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.Ba0Qbvp0.js">
    <link rel="modulepreload" href="/assets/chunks/framework.Cp3V7vRL.js">
    <link rel="modulepreload" href="/assets/paper_Fast EfficientDet An Efficient Pedestrian Detection Network.md.DkYBO058.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5a346dfe><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5a346dfe data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-d83f3580><div class="container" data-v-d83f3580><div class="title" data-v-d83f3580><div class="VPNavBarTitle" data-v-d83f3580 data-v-86d1bed8><a class="title" href="/" data-v-86d1bed8><!--[--><!--]--><!----><!--[-->ANIIAN&#39;S DIARY<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-d83f3580><div class="curtain" data-v-d83f3580></div><div class="content-body" data-v-d83f3580><!--[--><!--]--><div class="VPNavBarSearch search" data-v-d83f3580><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-d83f3580 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/index.html" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>首页</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/learn-life/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>生活</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/algorithm/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>算法</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/model/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>模型</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/paper/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>论文</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/understanding/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>理解深度学习</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-d83f3580 data-v-e6aabb21><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-e6aabb21 data-v-cbbe1149 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-cbbe1149><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-cbbe1149><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-d83f3580 data-v-d0bd9dde data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-9c007e85><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-9c007e85><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-d0bd9dde><div class="item appearance" data-v-d0bd9dde><p class="label" data-v-d0bd9dde>Appearance</p><div class="appearance-action" data-v-d0bd9dde><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-d0bd9dde data-v-cbbe1149 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-cbbe1149><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-cbbe1149><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-d83f3580 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav fixed reached-top" data-v-5a346dfe data-v-f84a0989><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-f84a0989 data-v-1c15a60a><button data-v-1c15a60a>Return to top</button><!----></div></div><!----><div class="VPContent" id="VPContent" data-v-5a346dfe data-v-669faec9><div class="VPDoc has-aside" data-v-669faec9 data-v-6b87e69f><!--[--><!--]--><div class="container" data-v-6b87e69f><div class="aside" data-v-6b87e69f><div class="aside-curtain" data-v-6b87e69f></div><div class="aside-container" data-v-6b87e69f><div class="aside-content" data-v-6b87e69f><div class="VPDocAside" data-v-6b87e69f data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-d330b1bb><div class="content" data-v-d330b1bb><div class="outline-marker" data-v-d330b1bb></div><div class="outline-title" role="heading" aria-level="2" data-v-d330b1bb>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-d330b1bb><span class="visually-hidden" id="doc-outline-aria-label" data-v-d330b1bb> Table of Contents for current page </span><ul class="root" data-v-d330b1bb data-v-d0ee3533><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-6b87e69f><div class="content-container" data-v-6b87e69f><!--[--><!--]--><!----><main class="main" data-v-6b87e69f><div style="position:relative;" class="vp-doc _paper_Fast%20EfficientDet%20An%20Efficient%20Pedestrian%20Detection%20Network" data-v-6b87e69f><div><h3 id="快速efficientdet-一种高效的行人检测网络" tabindex="-1">快速EfficientDet：一种高效的行人检测网络 <a class="header-anchor" href="#快速efficientdet-一种高效的行人检测网络" aria-label="Permalink to &quot;快速EfficientDet：一种高效的行人检测网络&quot;">​</a></h3><hr><h2 id="_1-标题" tabindex="-1">1. 标题 <a class="header-anchor" href="#_1-标题" aria-label="Permalink to &quot;1. 标题&quot;">​</a></h2><ul><li><strong>原文标题</strong>: Fast EfficientDet: An Efficient Pedestrian Detection Network</li><li><strong>中文标题</strong>: 快速EfficientDet：一种高效的行人检测网络</li></ul><hr><h2 id="_2-摘要" tabindex="-1">2. 摘要 <a class="header-anchor" href="#_2-摘要" aria-label="Permalink to &quot;2. 摘要&quot;">​</a></h2><h3 id="英文摘要" tabindex="-1">英文摘要 <a class="header-anchor" href="#英文摘要" aria-label="Permalink to &quot;英文摘要&quot;">​</a></h3><p>As an essential application in object detection, pedestrian detection has received extensive attention in many areas such as autonomous driving, video surveillance, and criminal investigation. With the rapid development of deep learning, pedestrian detection has made significant progress. However, when faced with multi-scale target pedestrians and dense crowds, false and missed detections are prone to occur, affecting accuracy. To overcome this problem, this study presents a multi-scale object detection network (Fast EfficientDet), based on an improved EfficientDet. Firstly, the backbone network EfficientNet is improved, and some of the deepwise separable convolutions that affect the speed of the model in the early training stage are discarded. At the same time, the Mish activation function is introduced to speed up the model&#39;s training. Secondly, a new feature pyramid-network Skip-BiFPN is proposed. Based on BiFPN, a cross-layer data stream is added to integrate the object&#39;s semantic and location information. In the face of complex environments, the network can better detect objects with large differences in size. Finally, the DIoU calculation method is introduced in the NMS post-processing. The suppression problem between the candidate frames is better handled by referring to the center point distance to solve object occlusion. Compared to the original EfficientDet series algorithm, the Fast EfficientDet-D0 obtained the best mAP of 84.98%, and the training speed increased by 15%. Compared to other algorithms, the Fast EfficientDet model has better performance.</p><h3 id="中文摘要" tabindex="-1">中文摘要 <a class="header-anchor" href="#中文摘要" aria-label="Permalink to &quot;中文摘要&quot;">​</a></h3><p>作为目标检测中的一项重要应用，行人检测在自动驾驶、视频监控和刑事侦查等诸多领域受到广泛关注。随着深度学习的快速发展，行人检测取得了显著进展。然而，面对多尺度目标行人以及密集人群时，容易出现误检和漏检情况，影响检测准确性。为克服这一问题，本研究提出一种基于改进EfficientDet的多尺度目标检测网络（Fast EfficientDet）。首先，对主干网络EfficientNet进行改进，舍弃部分在训练早期影响模型速度的深度可分离卷积，同时引入Mish激活函数以加快模型训练速度。其次，提出一种新的特征金字塔网络Skip - BiFPN。在BiFPN的基础上增加跨层数据流，整合对象的语义和位置信息，使其在复杂环境下能更好地检测尺寸差异较大的对象。最后，在NMS后处理中引入DIoU计算方法，通过参考中心点距离更好地处理候选框之间的抑制问题，以解决对象遮挡情况。与原始EfficientDet系列算法相比，Fast EfficientDet - D0获得了84.98%的最佳mAP，且训练速度提高了15%。与其他算法相比，Fast EfficientDet模型具有更好的性能。</p><hr><h2 id="_3-作者" tabindex="-1">3. 作者 <a class="header-anchor" href="#_3-作者" aria-label="Permalink to &quot;3. 作者&quot;">​</a></h2><ul><li><strong>姓名</strong>: M. Y. Cao（曹梦圆）、J. Zhao（赵骥）</li><li><strong>背景</strong>: 均来自辽宁科技大学计算机科学与软件工程学院，在计算机视觉和深度学习领域有一定研究经验，致力于目标检测相关技术的研究与创新。</li><li><strong>相关论文</strong>: 可能在深度学习算法优化、目标检测应用等方面发表过相关学术论文，为本文的研究奠定了理论和实践基础。</li></ul><hr><h2 id="_4-关键词" tabindex="-1">4. 关键词 <a class="header-anchor" href="#_4-关键词" aria-label="Permalink to &quot;4. 关键词&quot;">​</a></h2><ul><li>EfficientDet: 一种先进的目标检测网络架构，具有高效性和可扩展性，本文基于其进行改进以应用于行人检测任务。</li><li>行人检测 (Pedestrian Detection): 计算机视觉领域的重要研究方向，旨在检测图像或视频中的行人，为众多应用提供基础支持。</li><li>深度学习 (Deep Learning): 机器学习的一个分支，通过构建多层神经网络自动学习数据特征，在行人检测中发挥关键作用，本文利用其提升检测精度和效率。</li><li>特征金字塔网络 (Feature Pyramid Network): 用于多尺度特征融合的网络结构，有助于检测不同尺度的目标，本文提出的Skip - BiFPN是对其的改进，以更好适应行人检测需求。</li><li>非极大值抑制 (NMS): 目标检测中的后处理技术，用于去除冗余检测框，本文引入DIoU计算改进NMS，提高处理遮挡情况下候选框的准确性。</li></ul><hr><h2 id="_5-领域背景" tabindex="-1">5. 领域背景 <a class="header-anchor" href="#_5-领域背景" aria-label="Permalink to &quot;5. 领域背景&quot;">​</a></h2><h3 id="技术历史" tabindex="-1">技术历史 <a class="header-anchor" href="#技术历史" aria-label="Permalink to &quot;技术历史&quot;">​</a></h3><p>行人检测技术经历了从传统方法到深度学习方法的发展历程。早期传统方法主要依赖手动构建的特征，如方向梯度直方图（HOG）、哈尔特征（Haar）和局部二值模式（LBP）等，这些方法在简单场景下有一定效果，但面对复杂背景和遮挡时性能受限。随着深度学习的兴起，卷积神经网络（CNN）如AlexNet、VGGNet等被广泛应用于目标检测，极大提高了检测精度，后续又发展出R - CNN、Faster R - CNN等一系列基于深度学习的检测模型，推动了行人检测技术的进步。</p><h3 id="算法比较" tabindex="-1">算法比较 <a class="header-anchor" href="#算法比较" aria-label="Permalink to &quot;算法比较&quot;">​</a></h3><p>传统手动特征提取方法与深度学习方法相比，深度学习方法能够自动学习更复杂的特征表示，从而获得更高的检测精度。在深度学习方法内部，两阶段检测算法（如Faster R - CNN）通常具有较高的精度，但检测速度相对较慢；单阶段检测算法（如YOLO、SSD）速度较快，但精度稍低。不同算法在处理多尺度目标、遮挡问题以及计算资源需求等方面各有优劣。</p><h3 id="技术挑战" tabindex="-1">技术挑战 <a class="header-anchor" href="#技术挑战" aria-label="Permalink to &quot;技术挑战&quot;">​</a></h3><p>当前行人检测面临的主要技术挑战包括复杂场景中的遮挡问题，如行人之间相互遮挡或被其他物体遮挡；多尺度目标问题，由于行人在图像中距离相机远近不同，导致其在图像中的尺寸差异较大；以及密集人群场景下，如何准确区分和检测每个行人，同时保证检测的实时性，这些都是行人检测技术需要解决的关键问题。</p><hr><h2 id="_6-文献归纳" tabindex="-1">6. 文献归纳 <a class="header-anchor" href="#_6-文献归纳" aria-label="Permalink to &quot;6. 文献归纳&quot;">​</a></h2><h3 id="传统检测方法" tabindex="-1">传统检测方法 <a class="header-anchor" href="#传统检测方法" aria-label="Permalink to &quot;传统检测方法&quot;">​</a></h3><p>早期行人检测主要采用基于手动构建特征的方法，如Dalal和Triggs提出的HOG + SVM算法，通过计算图像局部区域的梯度变化信息作为特征，利用线性分类器进行检测，能有效应对小变形物体，但在复杂背景和遮挡情况下效果不佳。Felzenszwalb等人提出的可变形部件模型（DPM）是HOG的进一步扩展，可检测不同姿态行人。P. Dollar等人提出的集成通道特征（ICF）算法利用积分图技术计算特征通道，融合相关行人特征，但这些传统方法的模型计算特征耗时，分类器检测时间长，影响实时性。</p><h3 id="深度学习方法" tabindex="-1">深度学习方法 <a class="header-anchor" href="#深度学习方法" aria-label="Permalink to &quot;深度学习方法&quot;">​</a></h3><p>近年来，基于深度学习的方法成为主流。Zhang等人分析了Fast - RCNN在行人检测中的不足，提出利用区域建议网络（RPN）直接生成候选区域并结合提升树进行分类。Li等人使用两个子网络检测不同尺度行人，并采用尺度感知加权机制减少物体尺度对检测精度的影响。Yang等人提出的深度神经网络融合架构，先利用SSD网络生成不同大小和遮挡程度的行人候选，再进一步细化。Mendes等人提出统一深度神经网络实现多尺度对象快速检测，在不同中间网络层进行检测，节省内存和计算资源。Guan等人提出基于检测和跟踪构建3D行人虚拟空间的无监督方法，有效区分异常行为。</p><h3 id="网络架构优化" tabindex="-1">网络架构优化 <a class="header-anchor" href="#网络架构优化" aria-label="Permalink to &quot;网络架构优化&quot;">​</a></h3><p>EfficientDet作为一种先进的目标检测网络，其主干网络EfficientNet通过提出模型缩放方法，包括增加网络宽度、深度和输入图像分辨率等，在相同计算资源下提高了网络性能。BiFPN在特征金字塔网络（FPN）基础上进一步改进，通过优化跨尺度连接和提出加权融合方法，实现更多特征融合。本文基于这些网络架构进行优化，提出Fast EfficientDet，以更好地适应行人检测任务。</p><hr><h2 id="_7-切入点" tabindex="-1">7. 切入点 <a class="header-anchor" href="#_7-切入点" aria-label="Permalink to &quot;7. 切入点&quot;">​</a></h2><p>针对传统行人检测方法在复杂场景下准确性低以及现有深度学习算法存在的多尺度目标和遮挡处理不足等问题，以EfficientDet网络为基础，通过改进其主干网络、特征金字塔网络和非极大值抑制算法，提出Fast EfficientDet网络，旨在提高行人检测的准确性和效率，特别是在复杂背景、多尺度目标和密集人群等具有挑战性的场景中实现更优的检测性能。</p><hr><h2 id="_8-缺口分析" tabindex="-1">8. 缺口分析 <a class="header-anchor" href="#_8-缺口分析" aria-label="Permalink to &quot;8. 缺口分析&quot;">​</a></h2><h3 id="算法性能方面" tabindex="-1">算法性能方面 <a class="header-anchor" href="#算法性能方面" aria-label="Permalink to &quot;算法性能方面&quot;">​</a></h3><p>原始EfficientDet在处理多尺度行人目标时，浅层特征提取能力不足，导致对小尺度行人检测效果欠佳。在面对遮挡情况时，其检测性能也有待提高，容易出现漏检现象。</p><h3 id="训练效率方面" tabindex="-1">训练效率方面 <a class="header-anchor" href="#训练效率方面" aria-label="Permalink to &quot;训练效率方面&quot;">​</a></h3><p>EfficientDet网络层数较多，且在训练过程中使用大量深度可分离卷积，导致训练时占用过多视频内存，使得训练时间过长，效率低下，难以在资源有限的设备上快速训练模型。</p><h3 id="实际应用方面" tabindex="-1">实际应用方面 <a class="header-anchor" href="#实际应用方面" aria-label="Permalink to &quot;实际应用方面&quot;">​</a></h3><p>在实际复杂场景中，如密集人群场景，行人之间相互遮挡严重，同时存在不同尺度行人，现有的行人检测算法难以准确、快速地检测出所有行人，无法满足实际应用中对准确性和实时性的高要求。</p><hr><h2 id="_9-原因分析" tabindex="-1">9. 原因分析 <a class="header-anchor" href="#_9-原因分析" aria-label="Permalink to &quot;9. 原因分析&quot;">​</a></h2><h3 id="网络结构设计" tabindex="-1">网络结构设计 <a class="header-anchor" href="#网络结构设计" aria-label="Permalink to &quot;网络结构设计&quot;">​</a></h3><p>原始EfficientDet的主干网络EfficientNet在浅层使用过多深度可分离卷积，这种结构在实践中“计算量低但数据读写频繁”，导致GPU资源多用于数据读写而非计算，从而严重影响训练速度。</p><h3 id="特征融合方式" tabindex="-1">特征融合方式 <a class="header-anchor" href="#特征融合方式" aria-label="Permalink to &quot;特征融合方式&quot;">​</a></h3><p>BiFPN虽然在特征融合方面有所改进，但在处理复杂场景下多尺度特征融合时仍不够充分，缺乏对不同层语义和位置信息的全面整合，使得网络在检测不同尺度行人目标时性能受限。</p><h3 id="nms算法局限性" tabindex="-1">NMS算法局限性 <a class="header-anchor" href="#nms算法局限性" aria-label="Permalink to &quot;NMS算法局限性&quot;">​</a></h3><p>传统的非极大值抑制（NMS）算法仅依赖交并比（IoU）来判断候选框是否属于同一对象，在处理遮挡问题时存在缺陷。当两个对象实际距离较近但未完全重叠时，IoU可能较大，导致NMS误将其视为同一对象而删除其中一个，造成漏检。</p><hr><h2 id="_10-研究问题" tabindex="-1">10. 研究问题 <a class="header-anchor" href="#_10-研究问题" aria-label="Permalink to &quot;10. 研究问题&quot;">​</a></h2><p>如何改进EfficientDet网络，使其在复杂场景下（包括多尺度目标行人、密集人群和遮挡情况）能够更准确、快速地检测出行人，同时提高网络训练效率，降低对硬件资源的依赖，以满足实际应用中对行人检测的高精度和实时性要求。</p><hr><h2 id="_11-研究内容" tabindex="-1">11. 研究内容 <a class="header-anchor" href="#_11-研究内容" aria-label="Permalink to &quot;11. 研究内容&quot;">​</a></h2><h3 id="主干网络优化" tabindex="-1">主干网络优化 <a class="header-anchor" href="#主干网络优化" aria-label="Permalink to &quot;主干网络优化&quot;">​</a></h3><p>用普通3×3卷积替换EfficientNet中MBConv模块里的部分深度可分离卷积，减少网络层数，降低训练时的视频内存占用，同时引入Mish激活函数稳定网络梯度流，提高训练速度和模型准确性。</p><h3 id="特征金字塔网络改进" tabindex="-1">特征金字塔网络改进 <a class="header-anchor" href="#特征金字塔网络改进" aria-label="Permalink to &quot;特征金字塔网络改进&quot;">​</a></h3><p>提出Skip - BiFPN特征金字塔网络，在BiFPN基础上增加跨层数据流，实现上下层语义和位置信息的充分融合，更好地检测不同尺度目标，尤其增强了对小目标行人的检测能力。</p><h3 id="nms算法改进" tabindex="-1">NMS算法改进 <a class="header-anchor" href="#nms算法改进" aria-label="Permalink to &quot;NMS算法改进&quot;">​</a></h3><p>在传统NMS算法中引入DIoU计算方法，考虑候选框中心点距离，更准确判断两个框是否属于同一对象，有效解决行人检测中的遮挡问题，提高检测精度。</p><h3 id="实验验证与分析" tabindex="-1">实验验证与分析 <a class="header-anchor" href="#实验验证与分析" aria-label="Permalink to &quot;实验验证与分析&quot;">​</a></h3><p>在VOC 2012、Caltech和INRIA Person等数据集上进行实验，对比Fast EfficientDet与原始EfficientDet及其他主流算法的性能，包括检测精度（mAP）、训练速度等指标，同时进行消融实验分析各个改进模块对整体模型性能的影响。</p><hr><h2 id="_12-研究目的" tabindex="-1">12. 研究目的 <a class="header-anchor" href="#_12-研究目的" aria-label="Permalink to &quot;12. 研究目的&quot;">​</a></h2><h3 id="性能提升" tabindex="-1">性能提升 <a class="header-anchor" href="#性能提升" aria-label="Permalink to &quot;性能提升&quot;">​</a></h3><p>显著提高行人检测的准确性，特别是在复杂场景下减少误检和漏检，同时提升检测速度，以满足实时检测需求，如自动驾驶、视频监控等应用场景对行人检测的高精度和快速响应要求。</p><h3 id="效率优化" tabindex="-1">效率优化 <a class="header-anchor" href="#效率优化" aria-label="Permalink to &quot;效率优化&quot;">​</a></h3><p>通过改进网络结构和算法，减少模型训练时间和资源消耗，使模型能够在有限的硬件资源下高效训练，降低训练成本，提高模型的实用性和可扩展性。</p><h3 id="技术创新" tabindex="-1">技术创新 <a class="header-anchor" href="#技术创新" aria-label="Permalink to &quot;技术创新&quot;">​</a></h3><p>提出一种创新的行人检测网络架构和算法改进方案，为行人检测技术的发展提供新的思路和方法，推动相关领域的研究进展，同时为后续研究提供参考和借鉴。</p><h3 id="实际应用推动" tabindex="-1">实际应用推动 <a class="header-anchor" href="#实际应用推动" aria-label="Permalink to &quot;实际应用推动&quot;">​</a></h3><p>使改进后的行人检测模型更适用于实际复杂场景，提高行人检测技术在实际应用中的可靠性和有效性，为保障公共安全、智能交通等领域的发展提供技术支持。</p><hr><h2 id="_13-研究方法" tabindex="-1">13. 研究方法 <a class="header-anchor" href="#_13-研究方法" aria-label="Permalink to &quot;13. 研究方法&quot;">​</a></h2><h3 id="网络架构改进" tabindex="-1">网络架构改进 <a class="header-anchor" href="#网络架构改进" aria-label="Permalink to &quot;网络架构改进&quot;">​</a></h3><ul><li>对EfficientNet主干网络进行优化，实验性地确定替换MBConv模块中深度可分离卷积的最佳范围（2 - 4阶段），减少网络层数，提高训练速度。</li><li>设计Skip - BiFPN特征金字塔网络，增加跨层数据流，改进特征融合方式，通过加权融合使网络学习不同节点的重要性，增强多尺度特征表达能力。</li></ul><h3 id="算法改进" tabindex="-1">算法改进 <a class="header-anchor" href="#算法改进" aria-label="Permalink to &quot;算法改进&quot;">​</a></h3><p>在NMS算法中引入DIoU计算，通过计算候选框中心点距离与对角线长度的关系，结合IoU判断两个框是否属于同一对象，优化候选框筛选过程，减少遮挡导致的漏检。</p><h3 id="实验设置与训练策略" tabindex="-1">实验设置与训练策略 <a class="header-anchor" href="#实验设置与训练策略" aria-label="Permalink to &quot;实验设置与训练策略&quot;">​</a></h3><ul><li>采用VOC 2012数据集进行实验，将其随机划分为训练集、训练验证集和测试集，比例为81:9:10。同时在Caltech和INRIA Person数据集上进行对比测试。</li><li>基于PyTorch深度学习框架，在配备Intel Xeon E5系列处理器、128G内存、两块NVIDIA GTX TITAN XP显卡的DELL T7920图形工作站上进行实验。采用迁移学习和冻结训练策略，先进行50轮冻结训练，学习率设为(1e^{-3})，再进行50轮解冻训练，学习率设为(1e^{-4})，训练批次大小设为8，共训练100轮。</li></ul><h3 id="性能评估与分析" tabindex="-1">性能评估与分析 <a class="header-anchor" href="#性能评估与分析" aria-label="Permalink to &quot;性能评估与分析&quot;">​</a></h3><ul><li>通过计算平均精度均值（mAP）评估模型检测精度，比较不同算法在不同数据集上的性能表现，包括在处理单目标、多目标、遮挡、密集人群、小目标等不同场景下的检测效果。</li><li>分析模型训练时间，对比Fast EfficientDet与原始EfficientDet在相同硬件条件下的训练速度，验证改进措施对训练效率的提升效果。同时进行消融实验，逐一添加改进模块，评估每个模块对模型整体性能（mAP）的贡献。</li></ul><hr><h2 id="_14-最大创新点" tabindex="-1">14. 最大创新点 <a class="header-anchor" href="#_14-最大创新点" aria-label="Permalink to &quot;14. 最大创新点&quot;">​</a></h2><h3 id="网络结构创新" tabindex="-1">网络结构创新 <a class="header-anchor" href="#网络结构创新" aria-label="Permalink to &quot;网络结构创新&quot;">​</a></h3><p>提出Skip - BiFPN特征金字塔网络，创新性地引入跨层数据流，实现多层多节点融合学习，充分利用上下层语义和位置信息，有效增强了网络对多尺度行人目标的检测能力，尤其是在处理小目标行人时表现出色。</p><h3 id="算法改进-1" tabindex="-1">算法改进 <a class="header-anchor" href="#算法改进-1" aria-label="Permalink to &quot;算法改进&quot;">​</a></h3><p>在NMS算法中引入DIoU计算，考虑候选框中心点距离，改进了传统NMS仅基于IoU的局限性，能够更准确地处理遮挡情况下的候选框抑制问题，显著提高了行人检测的精度，减少了漏检情况。</p><h3 id="性能提升-1" tabindex="-1">性能提升 <a class="header-anchor" href="#性能提升-1" aria-label="Permalink to &quot;性能提升&quot;">​</a></h3><p>通过对EfficientDet的改进，Fast EfficientDet在检测精度和训练速度方面取得显著提升。Fast EfficientDet - D0模型的mAP达到84.98%，相比原始EfficientDet - D0提高了2.31%，同时训练速度提高了15%，在与其他主流算法对比中也展现出优越性能，为行人检测提供了更高效准确的解决方案。</p><h3 id="综合优化" tabindex="-1">综合优化 <a class="header-anchor" href="#综合优化" aria-label="Permalink to &quot;综合优化&quot;">​</a></h3><p>综合改进主干网络、特征金字塔网络和NMS算法，从多个方面优化行人检测网络，不仅提高了检测精度和速度，还在一定程度上降低了对硬件资源的依赖，使模型在实际应用中更具可行性和实用性。</p><hr><h2 id="_15-启发与展望" tabindex="-1">15. 启发与展望 <a class="header-anchor" href="#_15-启发与展望" aria-label="Permalink to &quot;15. 启发与展望&quot;">​</a></h2><h3 id="网络轻量化探索" tabindex="-1">网络轻量化探索 <a class="header-anchor" href="#网络轻量化探索" aria-label="Permalink to &quot;网络轻量化探索&quot;">​</a></h3><p>进一步研究如何在保持或提高检测精度的前提下，对网络进行轻量化处理，减少模型参数和计算量，使其能够在资源受限的设备（如移动设备、嵌入式设备）上更高效地运行，拓展行人检测技术的应用范围。</p><h3 id="多模态信息融合" tabindex="-1">多模态信息融合 <a class="header-anchor" href="#多模态信息融合" aria-label="Permalink to &quot;多模态信息融合&quot;">​</a></h3><p>考虑融合多种模态信息（如图像、激光雷达、语义信息等）进行行人检测，充分利用不同模态的互补性，提高检测系统在复杂环境下的鲁棒性和准确性，例如在恶劣天气或低光照条件下更准确地检测行人。</p><h3 id="模型适应性增强" tabindex="-1">模型适应性增强 <a class="header-anchor" href="#模型适应性增强" aria-label="Permalink to &quot;模型适应性增强&quot;">​</a></h3><p>研究如何使行人检测模型更好地适应不同场景和数据集的变化，减少对特定场景或数据集的依赖，提高模型的泛化能力。例如，开发自适应学习算法或预训练模型的微调策略，使其能够快速适应新的场景需求。</p><h3 id="实时性与准确性平衡" tabindex="-1">实时性与准确性平衡 <a class="header-anchor" href="#实时性与准确性平衡" aria-label="Permalink to &quot;实时性与准确性平衡&quot;">​</a></h3><p>继续探索在保证实时检测的同时进一步提高检测准确性的方法，优化算法和网络结构，以满足日益增长的对行人检测技术在自动驾驶、智能安防等领域的高要求，确保系统在复杂动态环境下能够及时准确地检测出行人，保障交通安全和公共安全。</p><h3 id="应用领域拓展" tabindex="-1">应用领域拓展 <a class="header-anchor" href="#应用领域拓展" aria-label="Permalink to &quot;应用领域拓展&quot;">​</a></h3><p>将改进后的行人检测技术拓展到更多领域，如智能交通中的行人流量统计与行为分析、智能家居中的人员监测与安全防护、虚拟现实中的虚拟场景交互等，为不同领域的发展提供技术支持，创造更多的应用价值。</p><hr><h2 id="_16-术语解释" tabindex="-1">16. 术语解释 <a class="header-anchor" href="#_16-术语解释" aria-label="Permalink to &quot;16. 术语解释&quot;">​</a></h2><h3 id="efficientdet" tabindex="-1">EfficientDet <a class="header-anchor" href="#efficientdet" aria-label="Permalink to &quot;EfficientDet&quot;">​</a></h3><p>一种先进的目标检测网络架构，通过模型缩放技术在不同资源约束下实现高效准确的目标检测，由主干网络EfficientNet、双向特征提取网络BiFPN和框/类预测网络组成，本文基于其进行改进用于行人检测。</p><h3 id="efficientnet" tabindex="-1">EfficientNet+ <a class="header-anchor" href="#efficientnet" aria-label="Permalink to &quot;EfficientNet+&quot;">​</a></h3><p>对EfficientNet主干网络的改进版本，通过用普通3×3卷积替换部分MBConv模块中的深度可分离卷积，并引入Mish激活函数，提高了网络训练速度和模型准确性，是Fast EfficientDet的重要组成部分。</p><h3 id="skip-bifpn" tabindex="-1">Skip - BiFPN <a class="header-anchor" href="#skip-bifpn" aria-label="Permalink to &quot;Skip - BiFPN&quot;">​</a></h3><p>一种新的特征金字塔网络，在BiFPN基础上增加跨层数据流，实现多层多节点融合学习，更好地整合了不同层的语义和位置信息，用于增强Fast EfficientDet对多尺度行人目标的检测能力，特别是对小目标行人的检测。</p><h3 id="diou-nms" tabindex="-1">DIoU - NMS <a class="header-anchor" href="#diou-nms" aria-label="Permalink to &quot;DIoU - NMS&quot;">​</a></h3><p>基于距离交并比（DIoU）的非极大值抑制</p></div></div></main><footer class="VPDocFooter" data-v-6b87e69f data-v-48f9bb55><!--[--><!--]--><div class="edit-info" data-v-48f9bb55><!----><div class="last-updated" data-v-48f9bb55><p class="VPLastUpdated" data-v-48f9bb55 data-v-7e05ebdb>Last updated: <time datetime="2025-03-27T03:04:39.000Z" data-v-7e05ebdb></time></p></div></div><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"algorithm_index.md\":\"PH4ThVQK\",\"algorithm_tulun.md\":\"D3aA7hl4\",\"index.md\":\"CNQXfB2O\",\"learn-life_20241121.md\":\"CoJVX333\",\"learn-life_20241122.md\":\"CPesXCN4\",\"learn-life_20241123.md\":\"DmYlUk2w\",\"learn-life_20241200.md\":\"DCE1X1kE\",\"learn-life_index.md\":\"C8e_yMHn\",\"learn-life_me.md\":\"DIOD2IOC\",\"learn-life_now.md\":\"BwC7MsuW\",\"learn-life_school2.md\":\"DLix7Y17\",\"model_alexnet.md\":\"B_j-EqC_\",\"model_efficientdet.md\":\"TyTZTS5l\",\"model_gan.md\":\"BD-MoK7t\",\"model_index.md\":\"BOXZ6ynm\",\"model_resnet.md\":\"BupIU4-q\",\"paper_1.md\":\"8s610QVY\",\"paper_comparison of object detection algorithms for livestock monitoring of sheep in uav images.md\":\"YdVfVayy\",\"paper_efficientdet for fabric defect detection based on edge computing.md\":\"vra9BPim\",\"paper_efficientdet.md\":\"FqHba7kE\",\"paper_efficientdetd0_deepsort.md\":\"D-P3IcCU\",\"paper_fast efficientdet an efficient pedestrian detection network.md\":\"DkYBO058\",\"paper_scalable and efficient object detection.md\":\"CZeMwKJV\",\"paper_index.md\":\"DhIrjZJF\",\"paper_prompts.md\":\"BLHTJZn4\",\"paper_read.md\":\"DEKjSlP4\",\"paper_test.md\":\"CN0zNVCL\",\"paper_webpages.md\":\"DZIf2k16\",\"paper_光谱.md\":\"Dm-Fq0C1\",\"paper_光谱技术在作物养分监测中的应用研究进展.md\":\"VSc_1wX4\",\"paper_光谱技术在农业中的应用.md\":\"C5AunKbU\",\"paper_基于便携式x射线荧光光谱速测的设施菜地土壤重金属污染诊断与评价.md\":\"CmafpWy2\",\"paper_磁力搅拌-电感耦合等离子体发射光谱测定石灰性土壤中交换性盐基.md\":\"DJt1hdAs\",\"paper_适于行人重识别的二分支efficientnet网络设计.md\":\"xvFt921d\",\"understanding_chapter1.md\":\"DsSxfxpu\",\"understanding_chapter10.md\":\"CcqANqXs\",\"understanding_chapter11.md\":\"DH5xQYVK\",\"understanding_chapter12.md\":\"YKLf-CR6\",\"understanding_chapter13.md\":\"5bVr2GFf\",\"understanding_chapter14.md\":\"vRICj6Os\",\"understanding_chapter15.md\":\"DHB2E3bu\",\"understanding_chapter16.md\":\"CfCKn4-2\",\"understanding_chapter17.md\":\"BWNDRcee\",\"understanding_chapter18.md\":\"BE2CiFjf\",\"understanding_chapter19.md\":\"pHugqteh\",\"understanding_chapter2.md\":\"D3_KXYfh\",\"understanding_chapter20.md\":\"xIETnmnm\",\"understanding_chapter21.md\":\"B_cm7pfB\",\"understanding_chapter22.md\":\"DojK0YFs\",\"understanding_chapter3.md\":\"DnVVjied\",\"understanding_chapter4.md\":\"DRvkWnFm\",\"understanding_chapter5.md\":\"Dm9iRd4P\",\"understanding_chapter6.md\":\"7oOjnEE3\",\"understanding_chapter7.md\":\"DBZDjoW7\",\"understanding_chapter8.md\":\"ZcAlvfst\",\"understanding_chapter9.md\":\"CLosE4Ak\",\"understanding_index.md\":\"Z2o0lCYL\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"ANIIAN'S DIARY\",\"description\":\"Record the learning of relevant deep learning, Linux, shell, etc.\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/index\"},{\"text\":\"生活\",\"link\":\"/learn-life/\"},{\"text\":\"算法\",\"link\":\"/algorithm/\"},{\"text\":\"模型\",\"link\":\"/model/\"},{\"text\":\"论文\",\"link\":\"/paper/\"},{\"text\":\"理解深度学习\",\"link\":\"/understanding/\"}],\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"}},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":false}");</script>
    
  </body>
</html>