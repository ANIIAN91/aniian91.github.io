### 1. 内容概述
本章节主要介绍了**深度神经网络**的概念，它是通过**组合多个神经网络层**构建而成的。本章解释了如何从简单的神经网络逐步构建出深度神经网络，强调了**深度**在神经网络中的意义，并探讨了深度神经网络与**浅层神经网络**的区别，同时介绍了使用**矩阵表示法**来简化对深度神经网络的描述。

### 2. 章节架构
- **4.1 Composing neural networks (组合神经网络)**：本节讲解了如何通过将**多个神经网络层连接**在一起来构建更复杂的网络。这种组合是构建深度神经网络的基础。
- **4.2 From composing networks to deep networks (从组合网络到深度网络)**：本节进一步解释了通过**堆叠更多的隐藏层**，将组合的神经网络发展成为真正的**深度神经网络**。它强调了“深度”指的是**隐藏层的数量**。
- **4.3 Deep neural networks (深度神经网络)**：本节正式介绍了**深度神经网络**的概念，并指出**现代网络可以拥有超过一百层**，每层包含数千个隐藏单元。还提到了**网络的宽度（每层的隐藏单元数）** 和**深度（隐藏层的数量）**，以及**总隐藏单元数作为网络容量的度量**。
    - **4.3.1 Hyperparameters (超参数)**：虽然是 4.3 的一个小节，但值得强调的是，本节提到了**隐藏单元的数量（宽度）** 和**隐藏层的数量（深度）** 是深度神经网络的重要**超参数**。
- **4.4 Matrix notation (矩阵表示法)**：本节介绍了如何使用**矩阵**来简洁地表示神经网络中的**线性变换和计算**。这对于理解和实现深度神经网络非常重要，尤其是在处理**多维输入和输出**时。
- **4.5 Shallow vs. deep neural networks (浅层神经网络 vs. 深度神经网络)**：本节对比了**浅层神经网络（只有一个隐藏层）** 和**深度神经网络（多个隐藏层）**。讨论了深度可以带来 **更高的表达能力**，能够学习更复杂的函数，并提及了深度神经网络的**线性区域数量**可以非常庞大。

### 3. 专有名词

| 原文                         | 翻译      | 说明                                                                                        |
| -------------------------- | ------- | ----------------------------------------------------------------------------------------- |
| Composing neural networks  | 组合神经网络  | 将多个神经网络层连接在一起，形成更复杂的网络结构的过程。                                                              |
| Deep neural networks       | 深度神经网络  | 拥有**多个隐藏层**的神经网络。                                                                         |
| Shallow neural networks    | 浅层神经网络  | 通常指**只有一个隐藏层**的神经网络。                                                                      |
| Hidden layer               | 隐藏层     | 神经网络中位于输入层和输出层之间的层，包含多个**隐藏单元（神经元）**。                                                     |
| Input layer                | 输入层     | 神经网络中接收**输入数据**的层。                                                                        |
| Output layer               | 输出层     | 神经网络中产生**最终预测结果**的层。                                                                      |
| Width of the network       | 网络宽度    | 指的是神经网络中**每一层隐藏层包含的隐藏单元（神经元）的数量**。                                                        |
| Depth of the network       | 网络深度    | 指的是神经网络中**隐藏层的数量**。                                                                       |
| Capacity (of the network)  | 容量（网络的） | 指的是神经网络可以学习的**函数复杂程度**。通常与网络的总隐藏单元数相关。                                                    |
| Matrix notation            | 矩阵表示法   | 使用**矩阵**来表示神经网络中的参数（权重和偏置）以及输入、输出和中间计算，可以简化公式和运算。                                         |
| Linear transformation      | 线性变换    | 在神经网络中，一个神经元的输入通常是前一层神经元输出的**线性组合**（加权求和并加上偏置）。                                           |
| Activation function        | 激活函数    | 在神经网络的每个神经元的线性变换之后应用的一个**非线性函数**，用于引入非线性性，使得网络可以学习复杂的模式。原文中虽然没有在第四章详细定义，但它是理解神经网络工作原理的关键。 |
| Piecewise linear functions | 分段线性函数  | 浅层神经网络可以描述的函数类型。深度神经网络通过组合多个分段线性函数，可以逼近更复杂的函数。                                            |

### 4. 关键知识点
- **深度是通过堆叠多个隐藏层实现的**。更多的隐藏层使得神经网络能够学习到**更抽象、更复杂的特征**，从而提高模型的表达能力。
- **深度神经网络具有比浅层神经网络更强的表达能力**。理论上，浅层神经网络可以逼近任何连续函数（通用逼近定理），但实际应用中，深度网络往往能更有效地学习复杂的模式。
- **网络的宽度和深度是重要的超参数，决定了网络的容量**。需要根据具体任务和数据选择合适的宽度和深度。
- **矩阵表示法是描述和计算深度神经网络的有效工具**。它能够简化复杂的网络结构和运算过程，方便进行数学推导和程序实现。
- **深度神经网络能够学习具有大量线性区域的函数**。这解释了它们为什么能够拟合非常复杂的数据关系。

### 5. 关键概念
- **组合性 (Compositionality)**：深度神经网络的核心思想是通过**组合简单的操作（例如，线性变换和非线性激活）** 来构建复杂的函数。每一层都对前一层的输出进行变换，逐渐提取出输入数据的高级特征。这就像搭积木一样，简单的组件可以搭建出复杂的结构。
- **表示学习 (Representation Learning)**：深度神经网络的每一层都在学习对输入数据的一种**新的表示**。随着网络深度的增加，学习到的表示也越来越抽象，越来越有利于最终的任务（例如，分类或回归）。例如，在图像识别中，浅层可能学习到边缘和纹理，而深层可能学习到物体的部件甚至整个物体。
- **抽象层次 (Levels of Abstraction)**：深度神经网络通过多层结构实现了对数据的**多层次抽象**。每一层都在前一层的基础上进行学习，逐渐提取出数据中更深层次的规律。这类似于人类理解事物的方式，从感知到的基本特征到理解更高级的概念。

### 6. 总结与启示
本章介绍了**深度神经网络的基本概念和构建方式**，强调了**深度**对于提升模型表达能力的重要性。理解了如何通过**组合神经网络层**以及**深度和宽度**的概念，有助于我们更好地理解各种深度学习模型的设计原理。**矩阵表示法**的学习也为我们后续深入理解模型的数学基础和代码实现打下了基础。

本章的主要启示在于：
- **更深的网络结构通常能够学习更复杂的问题**。
- **理解网络的深度和宽度是设计和调整深度学习模型的关键**。
- **掌握矩阵表示法对于理解和实现深度学习模型至关重要**。

