# 第二章：监督学习

## 1. 线性回归模型

线性回归模型假设输入特征与输出目标之间存在线性关系。模型的目标是学习一组参数，使得模型的预测值尽可能接近真实值。

### 模型定义

对于单一特征的线性回归模型，其数学表达式为：

$$
y = \phi_0 + \phi_1 x 
$$

其中：
- $y$ 是模型的预测值（输出目标）
- $x$ 是输入特征
- $\phi_0$ 是 y 轴截距
- $\phi_1$ 是斜率

参数 $\phi = [\phi_0, \phi_1]^T$ 决定了模型的预测结果。

对于多特征的线性回归模型，其数学表达式为：

$$
y = \phi_0 + \phi_1 x_1 + \phi_2 x_2 + ... + \phi_n x_n
$$

其中：
- $y$ 是模型的预测值（输出目标）
- $x_1, x_2, ..., x_n$ 是 n 个输入特征
- $\phi_0$ 是 y 轴截距
- $\phi_1, \phi_2, ..., \phi_n$ 是对应特征的权重

参数 $\phi = [\phi_0, \phi_1, \phi_2, ..., \phi_n]^T$ 决定了模型的预测结果。

### 损失函数

为了评估模型的拟合程度，我们需要定义一个损失函数来衡量模型预测值与真实值之间的差异。线性回归模型常用的损失函数是均方误差 (MSE):

$$
L[\phi] = \frac{1}{I} \sum_{i=1}^{I} (f[x_i, \phi] - y_i)^2
$$

其中:
- $L[\phi]$ 是损失函数
- $I$ 是训练样本的数量
- $f[x_i, \phi]$ 是模型对第 $i$ 个样本的预测值
- $y_i$ 是第 $i$ 个样本的真实值

均方误差越小，说明模型的拟合程度越好。

### 参数优化

为了找到最佳的参数值，我们需要最小化损失函数。梯度下降算法是一种常用的优化算法，它通过沿着损失函数梯度的反方向更新参数来最小化损失函数。

## 2. 梯度下降算法

梯度下降算法是一种迭代优化算法，其目标是找到一组参数，使得损失函数最小化。

### 基本思想

梯度下降算法的核心思想是沿着损失函数梯度的反方向更新参数。损失函数的梯度表示损失函数在参数空间中变化最快的方向，因此沿着梯度的反方向更新参数可以最快地降低损失函数值。

### 算法步骤

梯度下降算法的步骤如下：

1. 初始化参数 $\phi$
2. 重复以下步骤直到损失函数收敛：
   - 计算损失函数对参数 $\phi$ 的梯度 $\nabla L[\phi]$
   - 更新参数 $\phi \leftarrow \phi - \alpha \nabla L[\phi]$，其中 $\alpha$ 是学习率，控制参数更新的步长



## 3. 非凸损失函数

非凸损失函数是指存在多个局部最小值的损失函数。

### 定义

如果一个函数存在多个局部最小值，则该函数是非凸的。局部最小值是指在该点附近，函数值都大于该点的函数值。

### 挑战

对于非凸损失函数，梯度下降算法可能会陷入局部最小值，无法找到全局最优解。这是因为梯度下降算法只保证找到一个局部最小值，而不能保证找到全局最小值。



## 4. 随机梯度下降 (SGD)

随机梯度下降 (SGD) 算法是对梯度下降算法的改进，它每次迭代只使用一部分数据来计算梯度。

### 基本思想

SGD 算法的基本思想是每次迭代只使用一部分数据（称为一个 batch）来计算梯度，而不是使用全部数据。这样可以大大加快算法的速度，并且由于引入了随机性，可以更容易地逃离局部最小值。

### 优点

SGD 算法比梯度下降算法更快，并且由于引入了随机性，可以更容易地逃离局部最小值。


## 5. 动量 (Momentum)

动量是一种优化技巧，通过考虑参数更新的历史信息来加速梯度下降算法。

### 基本思想

动量算法维护一个速度向量，该向量是过去梯度的加权平均值。参数更新时，不仅考虑当前梯度，还考虑速度向量。这样可以使参数更新更加平滑，并且可以更快地收敛到最优解。

### 算法

动量算法的更新规则如下：

$$
v_t = \beta v_{t-1} + (1 - \beta) \nabla L[\phi_t] \\
\phi_{t+1} = \phi_t - \alpha v_t
$$

其中：
- $v_t$ 是速度向量
- $\beta$ 是动量系数，控制过去梯度对当前速度的影响程度
- $\alpha$ 是学习率

## 6. 训练算法超参数

训练算法超参数是指训练算法中需要手动设置的参数，例如学习率、batch 大小和动量系数。

### 定义

超参数是指训练算法中需要手动设置的参数，它们不参与模型的训练过程。

### 重要性

超参数的选择对模型的性能有很大影响。选择合适的超参数可以使模型更快地收敛到最优解，并提高模型的泛化能力。

### 超参数搜索

通常需要进行超参数搜索来找到最佳的超参数组合。超参数搜索是指尝试不同的超参数组合，并选择性能最好的组合。
